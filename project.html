<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Rock Paper Scissors game using hand recognition">
  <meta name="keywords" content="Rock Paper Scissors, Hand Recognition, TensorFlow.js, Machine Learning, Web Development">
  <meta name="author" content="Yuva Kotipalli">
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styleproject.css">
  <title>Rock Paper Scissors - Hand Recognition</title>
 <style>
  
    body {
      font-family: 'Poppins', sans-serif;
      color: #333;
      margin: 0;
      padding: 0;
      text-align: center;
    }
    header,footer {
      background: linear-gradient(to right, #831bcd, #f9620b);
      color: #f0f3f8;
      padding: 40px 0;
      text-align: center;
    }
    footer {
      margin: 5px 0;
      padding: 20px 0  ;
    }
    main {
      padding: 20px;
    }
    section {
      margin: 20px auto;
      padding: 20px;
      background-color: white;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
      border-radius: 8px;
      max-width: 900px;
    }
    h1, h2 {
      margin-bottom: 10px;
    }
    video {
      border: 2px solid #333;
      border-radius: 8px;
      width: 320px;
      height: 240px;
    }
    button {
      background-color: #831bcd;
      color: white;
      border: none;
      padding: 10px 20px;
      border-radius: 5px;
      cursor: pointer;
      font-size: 16px;
    }
    button:hover {
      background-color: #f9620b;
    }
    #result {
      margin-top: 20px;
      font-size: 18px;
      font-weight: bold;
      color: #831bcd;
    }  
    ul{
        text-align: left;
        list-style-type: disc ;
        padding: 0;
    }

 </style>
</head>
<body>
<center>
  <header>
    <h1 style="color: #fff">Rock Paper Scissors - Hand Recognition</h1>
  </header>

  <main>
    <section>
      <h2>Instructions</h2>
      <p style="color: rgb(29, 11, 145); font-size: 16px;">
        Use your hand gestures to play Rock, Paper, Scissors against the COMPUTER!
      </p>
      <ul>
        <li><strong>Rock:</strong> Make a fist.</li>
        <li><strong>Paper:</strong> Open your hand flat.</li>
        <li><strong>Scissors:</strong> Extend your index and middle fingers.</li>
      </ul>
    </section>

    <section>
      <h2 >Game Area</h2>
      <p>Allow camera access and use your gestures to play!</p>
    </section>

    <section>
      <h2 >Camera Feed</h2>
      <video id="video" autoplay></video>
      <canvas id="canvas" width="320" height="240" style="display:none;"></canvas>
      <div>
        <button onclick="captureAndPredict()">Capture & Predict</button>
      </div>
      <div id="result"></div>
    </section>
  </main>
</center>
  

  <!-- TensorFlow.js + MobileNet -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const resultDiv = document.getElementById('result');
    let model;

    async function setupCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        return new Promise((resolve) => {
          video.onloadedmetadata = () => resolve();
        });
      } catch (err) {
        console.error('Error accessing camera:', err);
        resultDiv.innerText = 'Error accessing camera: ' + err.message;
      }
    }

    async function loadModel() {
      try {
        model = await mobilenet.load();
        console.log('Model loaded successfully');
      } catch (err) {
        console.error('Error loading model:', err);
        resultDiv.innerText = 'Error loading model: ' + err.message;
      }
    }

    async function captureAndPredict() {
      if (!model) {
        resultDiv.innerText = 'Model not loaded yet.';
        return;
      }

      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0, 320, 240);

      const tensor = tf.browser.fromPixels(canvas);
      const predictions = await model.classify(tensor);

      // Placeholder AI choice
      const aiChoice = ['Rock', 'Paper', 'Scissors'][Math.floor(Math.random() * 3)];
      resultDiv.innerText = `AI chose: ${aiChoice}. (Placeholder - integrate gesture recognition here!)`;

      tensor.dispose();
    }

    async function main() {
      await setupCamera();
      await loadModel();
    }

    main();
  </script>
</body>
<footer>
    <p>&copy; 2024 Yuva Kotipalli. All rights reserved.</p>
    <p>Contact: <a href="mailto:yuva@example.com">yuva@example.com</a></p>
  </footer>
</html>
